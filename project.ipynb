{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing modules \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from model import Model\n",
    "from dataset import Dataset\n",
    "import copy\n",
    "import argparse\n",
    "import os\n",
    " \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--seed'], dest='seed', nargs=None, const=None, default=9, type=<class 'int'>, choices=None, required=False, help='Random Initiation (default: 9)', metavar=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='CMA_XD_VioDet')\n",
    "parser.add_argument('--rgb-list', default='list/rgb_new.list', help='list of rgb features ')\n",
    "parser.add_argument('--flow-list', default='list/flow_new.list', help='list of flow features')\n",
    "parser.add_argument('--audio-list', default='list/audio_new.list', help='list of audio features')\n",
    "parser.add_argument('--test-rgb-list', default='list/rgb_test_new.list', help='list of test rgb features ')\n",
    "parser.add_argument('--test-flow-list', default='list/flow_test_new.list', help='list of test flow features')\n",
    "parser.add_argument('--test-audio-list', default='list/audio_test_new.list', help='list of test audio features')\n",
    "parser.add_argument('--dataset-name', default='XD-Violence', help='dataset to train on XD-Violence')\n",
    "parser.add_argument('--gt', default='list/gt_new.npy', help='file of ground truth ')\n",
    "\n",
    "\n",
    "parser.add_argument('--modality', default='MIX_ALL', help='the type of the input, AUDIO,RGB,FLOW, MIX1, MIX2, '\n",
    "                                                          'or MIX3, MIX_ALL')\n",
    "parser.add_argument('--lr', type=float, default=0.0005, help='learning rate (default: 0.0005)')\n",
    "parser.add_argument('--batch-size', type=int, default=128, help='number of instances in a batch of data')\n",
    "parser.add_argument('--workers', default=8, help='number of workers in dataloader')\n",
    "parser.add_argument('--model-name', default='new_model__MIXALL', help='name to save model')\n",
    "parser.add_argument('--pretrained-ckpt', default=None, help='ckpt for pretrained model')\n",
    "parser.add_argument('--feature-size', type=int, default=1024+128, help='size of feature (default: 2048)')\n",
    "parser.add_argument('--num-classes', type=int, default=1, help='number of class')\n",
    "parser.add_argument('--max-seqlen', type=int, default=200, help='maximum sequence length during training')\n",
    "parser.add_argument('--max-epoch', type=int, default=50, help='maximum iteration to train (default: 50)')\n",
    "parser.add_argument('--seed', type=int, default=9, help='Random Initiation (default: 9)')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args(\"\")\n",
    "print(args)\n",
    "setup_seed(args.seed)\n",
    "\n",
    "\n",
    "train_data = Dataset(args, test_mode=False)\n",
    "\n",
    "train_loader = DataLoader(train_data,\n",
    "                            batch_size=args.batch_size, shuffle=True,\n",
    "                            num_workers=args.workers, pin_memory=True)\n",
    "print(len(train_loader.sampler))\n",
    "\n",
    "del train_data\n",
    "\n",
    "test_data = Dataset(args, test_mode=True)\n",
    "\n",
    "test_loader = DataLoader(test_data,\n",
    "                            batch_size=5, shuffle=False,\n",
    "                            num_workers=args.workers, pin_memory=True)\n",
    "\n",
    "del test_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args(\"\")\n",
    "model = Model(args)\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not os.path.exists('./ckpt'):\n",
    "    os.makedirs('./ckpt')\n",
    "\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=60, eta_min=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load weight of prev batch\n",
    "pretrained_dict = torch.load('ckpt/xd_a2v__.pkl',map_location=\"cpu\")\n",
    "model_dict = model.state_dict()\n",
    "if list(pretrained_dict.keys())[0].startswith(\"module.\"):\n",
    "    pretrained_dict = {k[7:]: v for k, v in pretrained_dict.items() if k[7:] in model_dict}\n",
    "else:\n",
    "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "    # 2. overwrite entries in the existing state dict\n",
    "    model_dict.update(pretrained_dict)\n",
    "    # 3. load the new state dict\n",
    "    model.load_state_dict(model_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model train\n",
    "import torch\n",
    "from loss import CLAS\n",
    "\n",
    "\n",
    "def train(dataloader, model, optimizer, criterion):\n",
    "    t_loss = 0.0\n",
    "    with torch.set_grad_enabled(True):\n",
    "        model.train()\n",
    "        for i, (inputs, label) in enumerate(dataloader):\n",
    "            seq_len = torch.sum(torch.max(torch.abs(inputs), dim=2)[0] > 0, 1)\n",
    "            inputs = inputs[:, :torch.max(seq_len), :]\n",
    "            inputs = inputs.float().cuda(non_blocking=True)\n",
    "            label = label.float().cuda(non_blocking=True)\n",
    "            logits = model(inputs)\n",
    "            loss = CLAS(logits, label, seq_len, criterion)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    " \n",
    "            t_loss+=(loss.item()*len(dataloader))\n",
    "\n",
    "    return t_loss/len(dataloader.sampler)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc, precision_recall_curve\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def test(dataloader, model, gt):\n",
    "    with torch.no_grad():\n",
    "        print(torch.cuda.is_available())\n",
    "        model.eval()\n",
    "        pred = torch.zeros(0).cuda()\n",
    "\n",
    "        for i, inputs in enumerate(dataloader):\n",
    "            inputs = inputs.cuda()\n",
    "            logits = model(inputs)\n",
    "            logits = torch.mean(logits, 0)\n",
    "            pred = torch.cat((pred, logits))\n",
    "        pred = list(pred.cpu().detach().numpy())\n",
    "        \n",
    "        precision, recall, th = precision_recall_curve(list(gt), np.repeat(pred, 16))\n",
    "        pr_auc = auc(recall, precision)\n",
    "        return pr_auc\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "best_ap = 0.0\n",
    "is_topk = True\n",
    "gt = np.load('list/gt_new.npy')\n",
    "st = time.time()\n",
    "for epoch in range(50):\n",
    "    cls_loss = train(train_loader, model, optimizer, criterion)\n",
    "    scheduler.step()\n",
    "    ap = test(test_loader, model, gt)\n",
    "    if ap > best_ap:\n",
    "        best_ap = ap\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    print('[Epoch {}/{}]: cls loss: {} | epoch AP: {:.4f}'.format(epoch + 1, 50, cls_loss, ap))\n",
    "    del cls_loss,ap\n",
    "print(\"The best accuracy is\", best_ap)   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(best_model_wts)\n",
    "torch.save(model.state_dict(), './ckpt/' + args.model_name  + '.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pretrained_dict = torch.load('ckpt/xd_a2v__.pkl',map_location=\"cpu\")\n",
    "model_dict = model.state_dict()\n",
    "if list(pretrained_dict.keys())[0].startswith(\"module.\"):\n",
    "    pretrained_dict = {k[7:]: v for k, v in pretrained_dict.items() if k[7:] in model_dict}\n",
    "else:\n",
    "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "    # 2. overwrite entries in the existing state dict\n",
    "    model_dict.update(pretrained_dict)\n",
    "    # 3. load the new state dict\n",
    "    model.load_state_dict(model_dict)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = time.time()\n",
    "pr_auc = test(test_loader, model, gt)\n",
    "time_elapsed = time.time() - st\n",
    "print('test AP: {:.4f}\\n'.format(pr_auc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
